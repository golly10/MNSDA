{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MetodosNoSupervisados-EjemploVariantesKMedias.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFf-0Eb6D58h"
      },
      "source": [
        "# Aplica variantes del algoritmo k-medias y otros métodos particionales \n",
        "En este notebook aprenderás a ejecutar varios métodos de agrupamiento particional, como alternativa al uso de k-medias. Seguiremos trabajando con las dos librerías Python utilizadas la semana anterior, *PyClustering* y *scikit-learn*, ya que cada una de ellas tiene implementaciones de métodos diferentes.\n",
        "## 1. Cambiar la inicialización de k-medias en ***PyClustering***\n",
        "En la primera parte del *notebook* utilizaremos la librería *PyClustering*, cuya [documentación en línea](https://pyclustering.github.io/docs/0.10.1/html/index.html) nos ayudará a configurar y ejecutar variantes del método k-medias. En esta librería, cada método de agrupamiento está definido en su propio subpaquete dentro de *cluster*. En este primer apartado, solo necesitamos importar un nuevo tipo de inicialización denominada *k-means++*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLVTAhVEDpeY"
      },
      "source": [
        "# La primera vez que se vaya a ejecutar este notebook es necesario instalar la librería pyclustering\n",
        "!pip install pyclustering\n",
        "from pyclustering.cluster.kmeans import kmeans, kmeans_visualizer\n",
        "from pyclustering.cluster.center_initializer import random_center_initializer, kmeans_plusplus_initializer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wi-3ZOlEFUza"
      },
      "source": [
        "Vamos a trabajar con un conjunto de datos precargado en *PyClustering*, donde los grupos están bastante dispersos. Para ver su distribución, podemos utilizar un visor proporcionado por la propia librería."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvAYZpjnGUtU"
      },
      "source": [
        "from pyclustering.utils import read_sample\n",
        "from pyclustering.samples.definitions import SIMPLE_SAMPLES\n",
        "from pyclustering.cluster import cluster_visualizer\n",
        "datos = read_sample(SIMPLE_SAMPLES.SAMPLE_SIMPLE3)\n",
        "visor = cluster_visualizer()\n",
        "visor.append_cluster(datos, color=\"blue\")\n",
        "grafico_datos = visor.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIXHpKX8HRrJ"
      },
      "source": [
        "La semana anterior vimos que antes de ejecutar el algoritmo k-medias en *PyClustering* necesitamos generar los centroides iniciales. Aparte de la inicialización aleatoria, la librería nos da la opción de utilizar una variante de k-medias denominada [*k-means++*](https://pyclustering.github.io/docs/0.10.1/html/db/de0/classpyclustering_1_1cluster_1_1center__initializer_1_1kmeans__plusplus__initializer.html#details). Este método proporciona una forma mejorada para determinar los centroides antes de ejecutar *k-means* u otro algoritmo de su misma \"familia\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWecB35NHriH"
      },
      "source": [
        "k = 4\n",
        "centroides_iniciales_optimizados = kmeans_plusplus_initializer(datos, k, random_state=0).initialize()\n",
        "print(centroides_iniciales_optimizados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSb-6nRjyxR7"
      },
      "source": [
        "Además de asignar los centroides obtenidos por este nuevo método, vamos a limitar el número de iteraciones del algoritmo a 5 con el parámetro *itermax*. De esta forma, podremos apreciar más claramente la influencia de los centroides iniciales, ya que el algoritmo tendrá pocas iteraciones para converger hacia los mejores centroides."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRgTpJbgyyP5"
      },
      "source": [
        "alg_kmeans_optimizado = kmeans(datos, centroides_iniciales_optimizados, itermax=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ICuCKBIRhh"
      },
      "source": [
        "Podemos representar gráficamente la ubicación de estos centroides para ver que se ajustan con bastante precisión a los grupos que se observan en el conjunto de datos, ya que esta inicialización pre-analiza la distancia entre puntos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNps3ZfLI3uA"
      },
      "source": [
        "visor.append_cluster(centroides_iniciales_optimizados, marker='*', markersize=10, color='green')\n",
        "grafico_datos = visor.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_mHZzpYFaIV"
      },
      "source": [
        "Vamos a inicializar también el conjunto de centroides de manera aleatoria para comparar cómo afecta al análisis de grupos con k-medias. Utilizamos el parámetro *random_state* para fijar una semilla aleatoria. Con ello, aseguramos que cualquier nueva ejecución de la función nos devolverá la misma inicialización de centroides."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol40XMktFZr-"
      },
      "source": [
        "centroides_iniciales_aleatorios = random_center_initializer(datos, k, random_state=0).initialize()\n",
        "print(centroides_iniciales_aleatorios)\n",
        "alg_kmeans_aleatorio = kmeans(datos, centroides_iniciales_aleatorios, itermax=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uon5Gj2iJIkG"
      },
      "source": [
        "Comprobamos con el visor cuál es la ubicación de estos centroides aleatorios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-xHiUgkJN4I"
      },
      "source": [
        "visor = cluster_visualizer()\n",
        "visor.append_cluster(datos, color=\"blue\")\n",
        "visor.append_cluster(centroides_iniciales_aleatorios, marker='X', markersize=10, color=\"red\")\n",
        "grafico_datos = visor.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "355eOJEtIMNd"
      },
      "source": [
        "A continuación, ejecutamos el análisis de grupos para cada instancia del algoritmo k-medias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v9gR9BEJK4k",
        "outputId": "b49af28f-e6cd-4219-fd02-1d8afe957c78"
      },
      "source": [
        "alg_kmeans_optimizado.process()\n",
        "alg_kmeans_aleatorio.process()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyclustering.cluster.kmeans.kmeans at 0x7f032dcbd910>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL0J841-JadE"
      },
      "source": [
        "Para ver el resultado, utilizamos el visor de grupos disponible en el propio algoritmo k-medias, que nos muestra de forma conjunta los grupos y los centroides. A pesar de realizar pocas iteraciones, el resultado agrupa de forma correcta las instancias del conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFIh3cVNDHHI"
      },
      "source": [
        "grafico_optimizado = kmeans_visualizer.show_clusters(datos, alg_kmeans_optimizado.get_clusters(), alg_kmeans_optimizado.get_centers())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LJqVx_VzorX"
      },
      "source": [
        "Si hacemos lo mismo con el algoritmo cuyos centroides iniciales eran aleatorios, vemos claramente que no es capaz de encontrar una distribución tan adecuada como en el caso anterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4Q8q68rGmjh"
      },
      "source": [
        "grafico_aleatorio = kmeans_visualizer.show_clusters(datos, alg_kmeans_aleatorio.get_clusters(), alg_kmeans_aleatorio.get_centers())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M78EsmVuDGyw"
      },
      "source": [
        "## 2. Utilizar variantes de k-medias en ***PyClustering***\n",
        "Hemos visto como cambiar uno de los elementos que afectan al algoritmo k-medias, su inicialización. En este apartado vamos a ver otros algoritmos que son variantes de k-medias puesto que modifican la forma en la que se determinan los centroides. Estos otros algoritmos son *k-medians* y *k-medoids*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk3UHJFBLEeX"
      },
      "source": [
        "from pyclustering.cluster.kmedians import kmedians\n",
        "from pyclustering.cluster.kmedoids import kmedoids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLfpwrcXLKxC"
      },
      "source": [
        "En primer lugar, vamos a generar un conjunto de datos de dos variables y 50 puntos generados de forma aleatoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55jToREKFQF3"
      },
      "source": [
        "tam = 50\n",
        "datos = np.random.random((tam,2))\n",
        "x = datos[0:tam,0]\n",
        "y = datos[0:tam,1]\n",
        "plt.scatter(x, y)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNJrP3mhFrE4"
      },
      "source": [
        "Para k-medias, podemos realizar la inicialización optimizada como en el apartado anterior. A continuación, ejecutamos el algoritmo y visualizamos los grupos. Vamos a utilizar un semilla aleatoria para poder replicar esta inicialización más adelante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcLMDNVdF1GI"
      },
      "source": [
        "k = 5\n",
        "centroides_iniciales = random_center_initializer(datos,k,random_state=0).initialize()\n",
        "alg_kmeans = kmeans(datos, centroides_iniciales)\n",
        "alg_kmeans.process()\n",
        "grafico = kmeans_visualizer.show_clusters(datos, alg_kmeans.get_clusters(), alg_kmeans.get_centers())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW-Wo_4rPafm"
      },
      "source": [
        "Para k-medians, podemos utilizar los mismos centroides iniciales para comprobar que el cambio en la asignación de grupos se debe al re-cálculo de centroides. En este algoritmo, el centroide se calcula como la mediana en lugar de la media."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2D2m3GhOVL1"
      },
      "source": [
        "medians_iniciales = centroides_iniciales\n",
        "alg_kmedians = kmedians(datos, medians_iniciales)\n",
        "alg_kmedians.process()\n",
        "grafico = kmeans_visualizer.show_clusters(datos, alg_kmedians.get_clusters(), alg_kmedians.get_medians())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL4lqm_aRSto"
      },
      "source": [
        "Para k-medoids, los centroides van a corresponderse con puntos reales del conjunto de datos.En primer lugar, tenemos que indicarle al generador de centroides iniciales que devuelva los índices de los puntos elegidos en lugar de sus coordenadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lEp33Z9QjX9"
      },
      "source": [
        "medoids_iniciales = random_center_initializer(datos,k,random_state=0).initialize(return_index=True)\n",
        "alg_kmedoids = kmedoids(datos, medoids_iniciales)\n",
        "alg_kmedoids.process()\n",
        "\n",
        "visor = cluster_visualizer()\n",
        "visor.append_clusters(alg_kmedoids.get_clusters(), datos)\n",
        "visor.append_cluster(alg_kmedoids.get_medoids(), datos, markersize=14, marker='*', color='black')\n",
        "grafico = visor.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAPyqvJA1s6D"
      },
      "source": [
        "Los centroides finales de *k-medoids* son índices del conjunto de datos, aquellos elegidos como representantes de cada grupo. Por el contrario, en k-medias y *k-medians* se calculan en base a la asignación de grupos, por lo que se devuelven en forma de coordenadas. Lo más habitual es que no coincidan con puntos reales del conjunto de datos, aunque en el caso de *k-medians* es más posible que alguno sí lo sea. Podemos comprobarlo con el sigeuiente código."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjFY_Czh16rw"
      },
      "source": [
        "# Centroides en k-means\n",
        "print('Centroides en k-medias: punto, ¿está en el conjunto de datos?')\n",
        "centroides_kmeans = alg_kmeans.get_centers()\n",
        "for i in range(0, len(centroides_kmeans)):\n",
        "  c = centroides_kmeans[i]\n",
        "  print(c, c in datos)\n",
        "\n",
        "# Centroides en k-medians\n",
        "print('Centroides en k-medians: punto, ¿está en el conjunto de datos?')\n",
        "centroides_kmedians = alg_kmedians.get_medians()\n",
        "for i in range(0, len(centroides_kmedians)):\n",
        "  c = centroides_kmedians[i]\n",
        "  print(c, c in datos)\n",
        "\n",
        "# Centroides en k-medoids\n",
        "print('Centroides en k-medias: índice, punto')\n",
        "centroides_kmedoids = alg_kmedoids.get_medoids()\n",
        "for i in range(0, len(centroides_kmedoids)):\n",
        "  c = centroides_kmedoids[i]\n",
        "  print(c, datos[c])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3qWUIdsK10R"
      },
      "source": [
        "## 3. Cambiar la inicialización de k-medias en ***scikit-learn***\n",
        "Al igual que en *PyClustering*, es posible cambiar el método de inicialización para el algoritmo k-medias en *scikit-learn*. En este apartado veremos cómo hacerlo. Lo primero que necesitamos es importar el algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pSpCrjI-evy"
      },
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwETB9_jCan0"
      },
      "source": [
        "A continuación, creamos nuestro conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ5muetAChZ9"
      },
      "source": [
        "tam = 100\n",
        "datos = np.random.random((tam,2))\n",
        "x = datos[0:tam,0]\n",
        "y = datos[0:tam,1]\n",
        "plt.scatter(x, y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQuzuNxrCqYL"
      },
      "source": [
        "Lo siguiente que tenemos que hacer es crear la instancia del algoritmo k-medias. Si consultamos la [documentación de referencia](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans), Uno de sus parámetros es *init*. Este parámetro puede tomar dos valores: *'random** y *'k-means++'*. Actualmente, el valor por defecto es *k-means++*, pues se ha visto que funciona mejor que el método aleatorio. No obstante, podemos indicarlo expresamente en la llamada la función. Además, vamos a reducir el número máximo de iteraciones (parámetro *max_iter*) para ver más claramente el beneficio de esta inicialización frente a la aleatoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiDKuYd0C7qu"
      },
      "source": [
        "k = 4\n",
        "alg_kmeans_plusplus = KMeans(n_clusters=k, random_state=1, init='k-means++', max_iter=5)\n",
        "alg_kmeans_plusplus.fit(datos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWwjiCNMEdLb"
      },
      "source": [
        "Hacemos el mismo proceso, pero indicando que la inicialización sea aleatoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siALfzpvEzuW"
      },
      "source": [
        "alg_kmeans = KMeans(n_clusters=k, random_state=1, init='random', max_iter=5)\n",
        "alg_kmeans.fit(datos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEh8k2wOFM78"
      },
      "source": [
        "Vamos a definir una función que nos permita visualizar una agrupación determinada, de forma que podamos comparar la asignación de cada algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3AbdY_9FYUY"
      },
      "source": [
        "def visualizar_grupos_sklearn(x, y, etiquetas, centroides, k):\n",
        "  plt.scatter(x, y, c=etiquetas)\n",
        "  colores = np.arange(0, k)\n",
        "  plt.scatter(centroides[0:k,0], centroides[0:k,1], marker=\"*\", c=colores)\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4J447h-FsU5"
      },
      "source": [
        "Ya podemos visualizar los resultados de k-medias y de k-medias++."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_6-2W3AFwar"
      },
      "source": [
        "visualizar_grupos_sklearn(x, y, alg_kmeans_plusplus.labels_, alg_kmeans_plusplus.cluster_centers_, k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CllnQPMBHKKA"
      },
      "source": [
        "visualizar_grupos_sklearn(x, y, alg_kmeans.labels_, alg_kmeans.cluster_centers_, k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE4g-TgYI37Y"
      },
      "source": [
        "## 4. Ejecutar AffinityPropagation en ***scikit-learn***\n",
        "[AffinityPropagation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html#sklearn.cluster.AffinityPropagation) es otro algoritmo particional que está disponible en la librería *scikit-learn*. Este algoritmo, a diferencia de *k-medias*, no require indicar el número de grupos a descubrir (parámetro *k*). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aSjUjUlLbf7"
      },
      "source": [
        "from sklearn.cluster import AffinityPropagation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZbXh0MoLer1"
      },
      "source": [
        "Para ejecutarlo, seguimos el mismo procedimiento de configuración que con otros algoritmos de esta librería."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqNOZ-seLnE4"
      },
      "source": [
        "alg_aff_prop = AffinityPropagation()\n",
        "alg_aff_prop.fit(datos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4b3heC2MCWt"
      },
      "source": [
        "Para saber cuántos grupos ha identificado, podemos recuperar los el vector de centroides (*exemplars*) y ver su dimensión. Además, como estos centroides son puntos reales del conjunto de datos, podemos recuperar también el índice de la instancia del conjunto de datos con el cual se corresponde cada uno."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUgGcKejMS_v"
      },
      "source": [
        "exemplars = alg_aff_prop.cluster_centers_\n",
        "num_grupos = len(exemplars)\n",
        "print(num_grupos)\n",
        "indices = alg_aff_prop.cluster_centers_indices_\n",
        "print(indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esXrxR-lMTSz"
      },
      "source": [
        " Por úlitmo, probamos a visualizar la partición devuelta por este algoritmo con nuestra función de visualización."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWOQaqB6MYnx"
      },
      "source": [
        "visualizar_grupos_sklearn(x, y, alg_aff_prop.labels_, exemplars, num_grupos)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
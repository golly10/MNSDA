{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBLOF_ejemplo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CBOF para detección de anomalías\n",
        "\n",
        "Aplicamos el método CBLOF basado en agrupamiento para detección de anomalías.\n",
        "\n",
        "Utilizamos la librería PyOD que es una biblioteca de Python para detectar anomalías en datos multivariados. La biblioteca fue desarrollada por Yue Zhao."
      ],
      "metadata": {
        "id": "86bXDH5L7pa_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 1. Instalar la librería PyOD"
      ],
      "metadata": {
        "id": "kXHDAduP8jbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyOD"
      ],
      "metadata": {
        "id": "LiuBh5eW4IOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 2. Importamos las librerías que necesitamos"
      ],
      "metadata": {
        "id": "yMC_r9pk8o3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pyod.models.cblof import CBLOF\n",
        "from pyod.utils.data import generate_data\n",
        "from pyod.utils.example import visualize\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "j03i8nGs4Daq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 3. Generamos datos sintéticos. En este caso, vamos a trabajar con datos de entrenamiento y datos de test, tal y como se ha explicado en clase. Para tener un conjunto considerable de datos de forma rápida, vamos a generarlos utilizando el método generate_data que nos permite definir el número de instancias, las dimensiones y el porcentaje de outliers que queremos.\n",
        "\n",
        "Rercordamos que aunque el algoritmo no usará el atributo que determina si es una anomalía o no para realizar su procesamiento, las tenemos disponibles con la finalidad de comparar los resultados."
      ],
      "metadata": {
        "id": "jDF7Mmye88T2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QACrKl7v4CPV"
      },
      "outputs": [],
      "source": [
        "# Porcentaje de outliers que vamos a considerar\n",
        "contamination = 0.1  \n",
        "\n",
        "#Número de ejemplos de entrenamiento y test que vamos a utilizar\n",
        "n_train = 200  \n",
        "n_test = 100  \n",
        "\n",
        "# Generamos los datos, considerando 2 dimensiones y las características anteriores\n",
        "# Utilizamos como generador de datos aleatorios (random_state) la semilla 12, \n",
        "# para que en todas las pruebas obtengamos los mismos datos.\n",
        "X_train, X_test, y_train, y_test = generate_data(n_train=n_train, n_test=n_test, n_features=2, behaviour='new', contamination=contamination,random_state=12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 4. Visualizamos los datos que hemos generado para train (entrenamiento) y test (prueba), lo representamos en diferente color los puntos que son anomalías de los que no.\n"
      ],
      "metadata": {
        "id": "8ZQAnD6S-8Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creamos una nueva variable DataFrame para que incorpore en los datos de entrenamiento\n",
        "# el atributo la etiqueta de anomalía o no.\n",
        "# Lo usamos solamente para la representación, los datos que usará el modelo sigue\n",
        "#sin tener esa información\n",
        "XY_train = pd.DataFrame({\"Variable 1\": X_train[:,0], \"Variable 2\": X_train[:,1], \"Anomalía\": y_train})\n",
        "\n",
        "#Lo representamos gráficamente poniendo el color en función de si es anómalo o no\n",
        "plt.scatter(XY_train['Variable 1'], XY_train['Variable 2'], c=XY_train['Anomalía'])\n",
        "plt.xlabel('Variable 1')\n",
        "plt.ylabel('Variable 2')\n",
        "plt.title(\"Distribución de los datos training\")\n",
        "plt.show()\n",
        "\n",
        "#Creamos una nueva variable DataFrame para que incorpore en los datos de test \n",
        "# el atributo la etiqueta de anomalía o no solamente para la representación. \n",
        "# El conjunto de test que usaremos en el modelo sigue sin tener esa información\n",
        "XY_test = pd.DataFrame({\"Variable 1\": X_test[:,0], \"Variable 2\": X_test[:,1], \"Anomalía\": y_test})\n",
        "\n",
        "#Lo representamos gráficamente poniendo el color en función de si es anómalo o no\n",
        "plt.scatter(XY_test['Variable 1'], XY_test['Variable 2'], c=XY_test['Anomalía'])\n",
        "plt.xlabel('Variable 1')\n",
        "plt.ylabel('Variable 2')\n",
        "plt.title(\"Distribución de los datos test\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oTpwSCh8_AJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 4. Entrenamos el modelo CBLOF utilizando la librería pyOD\n",
        "\n",
        "Parámetros:\n",
        "\n",
        "    n_clusters: int, (defecto = 8).  El número de clústeres a formar, así como el número de centroides a generar.\n",
        "    \n",
        "    contamination: float (0., 0.5), (defecto = 0.1)) – La cantidad de contaminación del conjunto de datos. La proporción de valores atípicos en el conjunto de datos. Se utiliza cuando para definir el umbral en la función de decisión.\n",
        "    \n",
        "    clustering_estimator: Estimator, (defecto = None)). El algoritmo de agrupación en clústeres base para realizar la agrupación de los datos que se va a realizar. Se debe pasar un algoritmo de agrupamiento válido. El estimador debe tener API de sklearn estándar, fit() y predict(). El estimador debe tener atributos label_ y cluster_centers_. Si cluster_centers_ no está en los atributos una vez que se ajusta el modelo, se calcula como la media de las muestras en un conglomerado. Si no se fija se usa KMeans.\n",
        "    \n",
        "    alpha: float (0.5, 1), (defecto = 0.9). Coeficiente para decidir clústeres pequeños y grandes. La relación entre el número de muestras en clústeres grandes y el número de muestras en clústeres pequeños\n",
        "    \n",
        "    beta: int or float, (defecto = 5). Coeficinete para decidir los clústeres pequeños y grandes. Para una lista ordenada de clústeres  por tamaño: |C1|, |C2|, …, |Cn|, beta = |Ck|/|Ck-1|\n",
        "    \n",
        "    use_weights: bool, (defecto = False). Si es True, el tamaño de los clústeres son usadmos como pesos en el cálculo de las puntuaciones de las anomalías.\n",
        "    \n",
        "    check_estimator: bool, (defecto=False). Si es True, comprueba si el estimador base es consistente con el estandard sklearn.\n",
        "    \n",
        "    random_state: int, RandomState o None, (defecto=None). Si es un entero, random_state es la semilla usada para el generador de números aleatorios; si es una instancia de RandomState, random_state es el generador de números; si es None, el generador de números es la isntancia RandomState usada por np.random."
      ],
      "metadata": {
        "id": "I_N5DO7wIeAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indicamos que utilizamos el método CBLOF y lo entrenamos usando el método fit\n",
        "clf_name = 'CBLOF'\n",
        "clf = CBLOF(alpha=0.9, beta=5, check_estimator=False, clustering_estimator=None, contamination=0.1, n_clusters=8, n_jobs=None, random_state=None, use_weights=False)\n",
        "clf.fit(X_train)"
      ],
      "metadata": {
        "id": "BSdX3jQe9wHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 5. Obtenemos los valores predichos por el modelo para los datos de train y de test. Obtenemos tanto la etiqueta binaria que le asigna este método a cada instancia, como las puntuaciones que se le asignan. De nuevo, usamos los métodos dados por la librería PyOD."
      ],
      "metadata": {
        "id": "6sD7VIjyIytt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos las etiquetas y los scores para cada instancia de train.\n",
        "# Las etiquetas asignan un 0 a los datos normales y un 1 a las anomalías\n",
        "# Los scores son puntuaciones que usa el método para determinar si son o no anomalías en funcion de un umbral.\n",
        "y_train_pred = clf.labels_  \n",
        "y_train_scores = clf.decision_scores_  \n",
        "\n",
        "# Obtenemos las etiquetas y los scores para cada instancia de test.\n",
        "# Las etiquetas asignan un 0 a los datos normales y un 1 a las anomalías\n",
        "# Los scores son puntuaciones que usa el método para determinar si son o no anomalías en funcion de un umbral.\n",
        "y_test_pred = clf.predict(X_test)  \n",
        "y_test_scores = clf.decision_function(X_test) \n",
        "\n",
        "#Mostramos las etiquetas asignadas a cada instancia tanto reales como predichas \n",
        "print('Etiquetas reales datos train: ', y_train)\n",
        "print('Etiquetas reales datos test: ', y_test)\n",
        "\n",
        "print('Etiquetas predichas datos train: ', y_train_pred)\n",
        "print('Etiquetas predichas datos test: ', y_test_pred)"
      ],
      "metadata": {
        "id": "mnlidXyhImrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 6. Visualizamos los resultados para ver si el método ha reconocido adecuadamente todas las anomalías.\n"
      ],
      "metadata": {
        "id": "LY6i7yuAJvBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizamos los resultados de forma sencilla utilizando el método visualize\n",
        "# que tiene disponible PyOD y en el que solamente tenemos que pasarle los datos y\n",
        "# los valores predichos.\n",
        "\n",
        "visualize(clf_name, X_train, y_train, X_test, y_test, y_train_pred, y_test_pred, show_figure=True, save_figure=False)"
      ],
      "metadata": {
        "id": "E8fawqBh4Gg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comentario visualización:** se puede apreciar que en los datos de entrenamiento consigue detectar todas las anomalías que habíamos introducido. En el caso de test, también identifica correctamente todos los datos."
      ],
      "metadata": {
        "id": "vN6evpOOKqLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 7. Calculamos las medidas que hemos visto para evaluar el rendimiento del método, partiendo de la matriz de confusión y también usando directamente la librería skearn.metrics"
      ],
      "metadata": {
        "id": "BRfdvm18z6cP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostramos la matriz de confusión para datos de train\n",
        "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)\n",
        "plt.title(\"Datos de train\")\n",
        "plt.show()\n",
        "\n",
        "#Mostramos la matriz de confusión para datos de test\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)\n",
        "plt.title(\"Datos de test\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EGVJMc920FlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación vamos a mostrar la curva ROC-AUC, sensibilidad, especificidad y precisión."
      ],
      "metadata": {
        "id": "m0kygXaK0OJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculamos las medidas para train\n",
        "print('Medidas para train')\n",
        "print('------------------')\n",
        "#Calculamos la matriz de confusión\n",
        "cm = confusion_matrix(y_train,y_train_pred)\n",
        "print('Matriz de confusión : \\n', cm)\n",
        "total=sum(sum(cm))\n",
        "\n",
        "#Calculamos sensibilidad y especificidad desde la matriz de confusión\n",
        "sensitivity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "print('Sensibilidad : ', sensitivity )\n",
        "specificity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "print('Especificidad: ', specificity)\n",
        "precision = cm[1,1]/(cm[1,1]+cm[0,1])\n",
        "print('Precisión: ', precision)\n",
        "\n",
        "#Calculamos las otras métricas desde la librería\n",
        "print('ROC-AUC: ', roc_auc_score(y_train, y_train_pred, average=None))\n",
        "\n",
        "\n",
        "#Calculamos las medidas para test\n",
        "print('Medidas para test')\n",
        "print('------------------')\n",
        "#Calculamos la matriz de confusión\n",
        "cm = confusion_matrix(y_test,y_test_pred)\n",
        "print('Matriz de confusión : \\n', cm)\n",
        "total=sum(sum(cm))\n",
        "\n",
        "#Calculamos sensibilidad y especificidad desde la matriz de confusión\n",
        "sensitivity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "print('Sensibilidad : ', sensitivity )\n",
        "specificity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "print('Especificidad: ', specificity)\n",
        "precision = cm[1,1]/(cm[1,1]+cm[0,1])\n",
        "print('Precisión: ', precision)\n",
        "\n",
        "#Calculamos las otras métricas desde la librería\n",
        "print('ROC-AUC: ', roc_auc_score(y_test, y_test_pred, average=None))\n"
      ],
      "metadata": {
        "id": "bDh1uL6C0TUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comentario métricas:** se puede ver que para los datos de train y test se consigue una clasificación perfecta, donde la clasificación de las anomalías es de un 100% (sensibilidad), la clasificación de las clases normales, también es un 100% (especificidad), el área bajo la curva es también perfecta (valor 1.0) y el total de aciertos de la clase anómala con respecto a todo lo que se ha dicho que era anomálo es también del 100%.\n",
        "\n",
        "Aunque los resultados han sido excelentes, te animo a cambiar el número de clústeres o los parámetros alpha y beta para ver cómo afecta a los resultados obtenidos.\n",
        "  "
      ],
      "metadata": {
        "id": "ipYINZRQ0ZmY"
      }
    }
  ]
}
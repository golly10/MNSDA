{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COF_ejemplo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## COF para detección de anomalías\n",
        "\n",
        "Aplicamos el método COF basado en vecinos más cercanos para detección de anomalías.\n",
        "\n",
        "Utilizamos la librería PyOD que es una biblioteca de Python para detectar anomalías en datos multivariados. La biblioteca fue desarrollada por Yue Zhao."
      ],
      "metadata": {
        "id": "86bXDH5L7pa_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 1. Instalar la librería PyOD"
      ],
      "metadata": {
        "id": "kXHDAduP8jbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyOD"
      ],
      "metadata": {
        "id": "LiuBh5eW4IOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 2. Importamos las librerías que necesitamos"
      ],
      "metadata": {
        "id": "yMC_r9pk8o3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pyod.models.cof import COF \n",
        "from pyod.utils.data import generate_data\n",
        "from pyod.utils.example import visualize\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "j03i8nGs4Daq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 3. Generamos datos sintéticos. En este caso, vamos a trabajar con datos de entrenamiento y datos de test, tal y como se ha explicado en clase. Para tener un conjunto considerable de datos de forma rápida, vamos a generarlos utilizando el método generate_data que nos permite definir el número de instancias, las dimensiones y el porcentaje de outliers que queremos.\n",
        "\n",
        "Rercordamos que aunque el algoritmo no usará el atributo que determina si es una anomalía o no para realizar su procesamiento, las tenemos disponibles con la finalidad de comparar los resultados."
      ],
      "metadata": {
        "id": "jDF7Mmye88T2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QACrKl7v4CPV"
      },
      "outputs": [],
      "source": [
        "# Porcentaje de outliers que vamos a considerar\n",
        "contamination = 0.1  \n",
        "\n",
        "#Número de ejemplos de entrenamiento y test que vamos a utilizar\n",
        "n_train = 200  \n",
        "n_test = 100  \n",
        "\n",
        "# Generamos los datos, considerando 2 dimensiones y las características anteriores\n",
        "# Utilizamos como generador de datos aleatorios (random_state) la semilla 12, \n",
        "# para que en todas las pruebas obtengamos los mismos datos.\n",
        "X_train, X_test, y_train, y_test = generate_data(n_train=n_train, n_test=n_test, n_features=2, behaviour='new', contamination=contamination,random_state=12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 4. Visualizamos los datos que hemos generado para train (entrenamiento) y test (prueba), lo representamos en diferente color los puntos que son anomalías de los que no.\n"
      ],
      "metadata": {
        "id": "8ZQAnD6S-8Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creamos una nueva variable DataFrame para que incorpore en los datos de entrenamiento\n",
        "# el atributo la etiqueta de anomalía o no.\n",
        "# Lo usamos solamente para la representación, los datos que usará el modelo sigue\n",
        "#sin tener esa información\n",
        "XY_train = pd.DataFrame({\"Variable 1\": X_train[:,0], \"Variable 2\": X_train[:,1], \"Anomalía\": y_train})\n",
        "\n",
        "#Lo representamos gráficamente poniendo el color en función de si es anómalo o no\n",
        "plt.scatter(XY_train['Variable 1'], XY_train['Variable 2'], c=XY_train['Anomalía'])\n",
        "plt.xlabel('Variable 1')\n",
        "plt.ylabel('Variable 2')\n",
        "plt.title(\"Distribución de los datos training\")\n",
        "plt.show()\n",
        "\n",
        "#Creamos una nueva variable DataFrame para que incorpore en los datos de test \n",
        "# el atributo la etiqueta de anomalía o no solamente para la representación. \n",
        "# El conjunto de test que usaremos en el modelo sigue sin tener esa información\n",
        "XY_test = pd.DataFrame({\"Variable 1\": X_test[:,0], \"Variable 2\": X_test[:,1], \"Anomalía\": y_test})\n",
        "\n",
        "#Lo representamos gráficamente poniendo el color en función de si es anómalo o no\n",
        "plt.scatter(XY_test['Variable 1'], XY_test['Variable 2'], c=XY_test['Anomalía'])\n",
        "plt.xlabel('Variable 1')\n",
        "plt.ylabel('Variable 2')\n",
        "plt.title(\"Distribución de los datos test\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oTpwSCh8_AJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 4. Entrenamos el modelo COF utilizando la librería pyOD\n",
        "\n",
        "Parámetros:\n",
        "\n",
        "    n_neighbors : integer, (defecto = 20) - El número de vecinos que se van a utilizar.\n",
        "    \n",
        "    contamination: float (0., 0.5), (defecto = 0.1)) – La cantidad de contaminación del conjunto de datos. La proporción de valores atípicos en el conjunto de datos. Se utiliza cuando para definir el umbral en la función de decisión.\n",
        "    \n",
        "    method : string, (defecto='fast') - Los dos valores válidos para métodos son: 'fast': calcula todas las distancias por pares completas en una matriz, 'memory': calcula las distancias por pares solamente cuando es necesario.\n",
        "\n"
      ],
      "metadata": {
        "id": "I_N5DO7wIeAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indicamos que utilizamos el método COF y lo entrenamos usando el método fit\n",
        "clf_name = 'COF'\n",
        "clf = COF(n_neighbors=30, contamination = 0.1)\n",
        "clf.fit(X_train)"
      ],
      "metadata": {
        "id": "BSdX3jQe9wHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "596203a0-3021-4629-d2cd-ec2fb3827555"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "COF(contamination=0.1, method='fast', n_neighbors=None)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 5. Obtenemos los valores predichos por el modelo para los datos de train y de test. Obtenemos tanto la etiqueta binaria que le asigna este método a cada instancia, como las puntuaciones que se le asignan. De nuevo, usamos los métodos dados por la librería PyOD."
      ],
      "metadata": {
        "id": "6sD7VIjyIytt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos las etiquetas y los scores para cada instancia de train.\n",
        "# Las etiquetas asignan un 0 a los datos normales y un 1 a las anomalías\n",
        "# Los scores son puntuaciones que usa el método para determinar si son o no anomalías en funcion de un umbral.\n",
        "y_train_pred = clf.labels_  \n",
        "y_train_scores = clf.decision_scores_  \n",
        "\n",
        "# Obtenemos las etiquetas y los scores para cada instancia de test.\n",
        "# Las etiquetas asignan un 0 a los datos normales y un 1 a las anomalías\n",
        "# Los scores son puntuaciones que usa el método para determinar si son o no anomalías en funcion de un umbral.\n",
        "y_test_pred = clf.predict(X_test)  \n",
        "y_test_scores = clf.decision_function(X_test) \n",
        "\n",
        "\n",
        "#Mostramos las etiquetas asignadas a cada instancia tanto reales como predichas \n",
        "print('Etiquetas reales datos train: ', y_train)\n",
        "print('Etiquetas reales datos test: ', y_test)\n",
        "\n",
        "print('Etiquetas predichas datos train: ', y_train_pred)\n",
        "print('Etiquetas predichas datos test: ', y_test_pred)"
      ],
      "metadata": {
        "id": "mnlidXyhImrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 6. Visualizamos los resultados para ver si el método ha reconocido adecuadamente todas las anomalías.\n"
      ],
      "metadata": {
        "id": "LY6i7yuAJvBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizamos los resultados de forma sencilla utilizando el método visualize\n",
        "# que tiene disponible PyOD y en el que solamente tenemos que pasarle los datos y\n",
        "# los valores predichos.\n",
        "\n",
        "visualize(clf_name, X_train, y_train, X_test, y_test, y_train_pred, y_test_pred, show_figure=True, save_figure=False)"
      ],
      "metadata": {
        "id": "E8fawqBh4Gg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comentario visualización:** se puede apreciar que tanto en los datos de entrenamiento como en los de test, tenemos fallos tanto a la hora de detectar las anomalías como los datos normales."
      ],
      "metadata": {
        "id": "vN6evpOOKqLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paso 7. Calculamos las medidas que hemos visto para evaluar el rendimiento del método, partiendo de la matriz de confusión y también usando directamente la librería skearn.metrics"
      ],
      "metadata": {
        "id": "BRfdvm18z6cP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostramos la matriz de confusión para datos de train\n",
        "ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)\n",
        "plt.title(\"Datos de train\")\n",
        "plt.show()\n",
        "\n",
        "#Mostramos la matriz de confusión para datos de test\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_test_pred)\n",
        "plt.title(\"Datos de test\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EGVJMc920FlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación vamos a mostrar la curva ROC-AUC, sensibilidad, especificidad y precisión."
      ],
      "metadata": {
        "id": "m0kygXaK0OJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculamos las medidas para train\n",
        "print('Medidas para train')\n",
        "print('------------------')\n",
        "#Calculamos la matriz de confusión\n",
        "cm = confusion_matrix(y_train,y_train_pred)\n",
        "print('Matriz de confusión : \\n', cm)\n",
        "total=sum(sum(cm))\n",
        "\n",
        "#Calculamos sensibilidad y especificidad desde la matriz de confusión\n",
        "sensitivity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "print('Sensibilidad : ', sensitivity )\n",
        "specificity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "print('Especificidad: ', specificity)\n",
        "precision = cm[1,1]/(cm[1,1]+cm[0,1])\n",
        "print('Precisión: ', precision)\n",
        "\n",
        "#Calculamos las otras métricas desde la librería\n",
        "print('ROC-AUC: ', roc_auc_score(y_train, y_train_pred, average=None))\n",
        "\n",
        "\n",
        "#Calculamos las medidas para test\n",
        "print('Medidas para test')\n",
        "print('------------------')\n",
        "#Calculamos la matriz de confusión\n",
        "cm = confusion_matrix(y_test,y_test_pred)\n",
        "print('Matriz de confusión : \\n', cm)\n",
        "total=sum(sum(cm))\n",
        "\n",
        "#Calculamos sensibilidad y especificidad desde la matriz de confusión\n",
        "sensitivity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
        "print('Sensibilidad : ', sensitivity )\n",
        "specificity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "print('Especificidad: ', specificity)\n",
        "precision = cm[1,1]/(cm[1,1]+cm[0,1])\n",
        "print('Precisión: ', precision)\n",
        "\n",
        "#Calculamos las otras métricas desde la librería\n",
        "print('ROC-AUC: ', roc_auc_score(y_test, y_test_pred, average=None))\n"
      ],
      "metadata": {
        "id": "bDh1uL6C0TUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comentario métricas:** se puede ver que los datos de test obtiene mejores resultados que en train. En los datos de train la especifididad es más alta que la sensibilidad, lo que indica que clasifica mejor la clase normal que la anómala. La precisión entorno a un 40%, indica que de todo lo que dice que es anómalo, hay más ejemplos normales que anormales. Es decir, se detectan como anomalías datos que son normales. En aplicaciones críticas, estos fallos son preferibles a los fallos donde anomalías reales son identificadas como normales, pero este algoritmo también comete ese tipo de fallos, poniéndose de manifiesto con el valor de la sensibilidad entorno a un 40% también. En el caso del test los resultados son mejores, es capaz de identificar todas las anomalías, con un 100% de sensibilidad\", aunque comete errores en la clasificación de las clases normales (96.7%), esto nos lleva que la precisión sea de 76.92%, es decir, de todos lo que decimos que es anómalo, solamente el 76.92% lo es, el resto sería ejemplos normales.\n",
        "\n",
        "  El área de la curva ROC tenemos unos valores alrededor del 66.67%, para train, indicándonos que esa sería la probabilidad de clasificar correctamente los datos normales y las anomalías. Esta cifra se mejora en los datos de test, con un porcentaje de 98.33% de clasificar correctamente los ejemplos. \n",
        "  \n",
        "  Te animo a que consideres modificar los parámetros de COF por defecto, en este caso modifca el número de vecinos a 30, ¿han mejorado los resultados?, ¿y si pones 40?. \n",
        "  "
      ],
      "metadata": {
        "id": "ipYINZRQ0ZmY"
      }
    }
  ]
}